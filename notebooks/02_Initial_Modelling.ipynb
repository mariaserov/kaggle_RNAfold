{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "First, we need to decide what library can be used for handling data. I will encode sequences numerically, and want to have the option to handle them that way, scale to add different information (BPP, physical properties, distance, etc), and to handle them as graphs. The best one for this seems to be PyTorch (datatype - tensor), it also has the option of PyTorch Geometric. Another option would be TensorFlow/Keras, though it seems a bit harder to handle graphs. \n",
    "\n",
    "TO DO:\n",
    "- set up first NN with X as input and y (coordinates) as output\n",
    "- incorporate MSA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data (X & y)\n",
    "For now, these are prepared as tensors of one-hot-encoded sequence (padded to make sure they are of same length), and tensors of coordinates. MSA are not yet considered.\n",
    "Update: since embedding is used, the sequences are instead converted to tensors. The one-hot-encode code is kept below for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Module, MSELoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "train_seq = pd.read_csv(\"../toy_data/train_sequences.csv\")\n",
    "train_lbl = pd.read_csv(\"../toy_data/train_labels.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 2, 1, 3, 2, 3, 4, 1, 2, 4, 3, 1, 4, 1, 4, 1, 1, 4, 4, 3, 3, 1,\n",
       "        3, 4, 3, 3, 3, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nts = ['G', 'U', 'C', 'A', 'X', '-']\n",
    "mapping = {nt: idx+1 for idx, nt in enumerate(nts)}\n",
    "\n",
    "\n",
    "def tokenise_seq(seq, mapping=mapping):\n",
    "    seq_idx = [mapping[nt] for nt in seq]\n",
    "    seq_idx = torch.tensor(seq_idx)\n",
    "    return seq_idx\n",
    "\n",
    "X_list = [tokenise_seq(seq) for seq in train_seq['sequence']]\n",
    "X_tensor = pad_sequence(X_list, batch_first=True)\n",
    "\n",
    "X_tensor[0] # QC\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X: One-hot encode sequence and convert to tenshor\n",
    "\n",
    "# #seq = train_seq['sequence'][0] # to test\n",
    "\n",
    "# nts = ['G', 'U', 'C', 'A', 'X', '-']\n",
    "# mapping = {nt: idx for idx, nt in enumerate(nts)}\n",
    "\n",
    "# def one_hot_encode_seq(seq):\n",
    "\n",
    "#     ohe_seq = []\n",
    "\n",
    "#     for nt in seq:\n",
    "#         binary_l = [0] * len(nts)\n",
    "#         binary_l[mapping[nt]] = 1\n",
    "#         ohe_seq.append(binary_l)\n",
    "    \n",
    "#     ohe_torch = torch.tensor(ohe_seq, dtype=torch.float32)\n",
    "#     return ohe_torch\n",
    "\n",
    "# X_list = [one_hot_encode_seq(seq) for seq in train_seq['sequence']]\n",
    "# X_tensor = pad_sequence(X_list, batch_first=True) # pad sequences to same length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y: Convert coordinates to tensor\n",
    "\n",
    "train_lbl['base_ID'] = train_lbl['ID'].str.rsplit('_', n=1).str[0]\n",
    "\n",
    "y_list = []\n",
    "for idx in list(train_lbl['base_ID'].unique()):\n",
    "\n",
    "    coords = []\n",
    "    for res in range(len(train_lbl[train_lbl['ID'].str.startswith(idx)])):\n",
    "        coord = list(train_lbl.iloc[res, 3:6])\n",
    "        coords.append(coord)\n",
    "    \n",
    "    y_list.append(torch.tensor(coords, dtype=torch.float32))\n",
    "    \n",
    "y_tensor = pad_sequence(y_list, batch_first=True)\n",
    "\n",
    "y_tensor.size()[0:2] == X_tensor.size()[0:2] # check that it's formatted correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a padding mask\n",
    "\n",
    "attn_mask = []\n",
    "for seq in X_list:\n",
    "    mask = [False if i < len(seq) else True for i in range(X_tensor.size()[1])]\n",
    "    attn_mask.append(mask)\n",
    "\n",
    "attn_mask = torch.tensor(attn_mask)\n",
    "padding_mask = ~attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset & Dataloader\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "class Rnadataset(Dataset):\n",
    "    def __init__(self, X_tensor, y_tensor):\n",
    "        super().__init__()\n",
    "        self.X_tensor = X_tensor\n",
    "        self.y_tensor = y_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_tensor)\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        return self.X_tensor[index], self.y_tensor[index]\n",
    "    \n",
    "dataset = Rnadataset(X_tensor, y_tensor)\n",
    "\n",
    "train_size = int(len(dataset)*0.8)\n",
    "test_size = int(len(dataset)-train_size)\n",
    "\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.9356,  0.4105, -0.3889,  0.0239],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [ 0.1681, -1.9141, -0.7487,  1.1676],\n",
       "        [-0.9356,  0.4105, -0.3889,  0.0239],\n",
       "        [ 0.1681, -1.9141, -0.7487,  1.1676],\n",
       "        [-0.6137,  1.4808, -2.4116, -0.5547],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.9356,  0.4105, -0.3889,  0.0239],\n",
       "        [-0.6137,  1.4808, -2.4116, -0.5547],\n",
       "        [ 0.1681, -1.9141, -0.7487,  1.1676],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.6137,  1.4808, -2.4116, -0.5547],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.6137,  1.4808, -2.4116, -0.5547],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.6137,  1.4808, -2.4116, -0.5547],\n",
       "        [-0.6137,  1.4808, -2.4116, -0.5547],\n",
       "        [ 0.1681, -1.9141, -0.7487,  1.1676],\n",
       "        [ 0.1681, -1.9141, -0.7487,  1.1676],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [ 0.1681, -1.9141, -0.7487,  1.1676],\n",
       "        [-0.6137,  1.4808, -2.4116, -0.5547],\n",
       "        [ 0.1681, -1.9141, -0.7487,  1.1676],\n",
       "        [ 0.1681, -1.9141, -0.7487,  1.1676],\n",
       "        [ 0.1681, -1.9141, -0.7487,  1.1676],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417],\n",
       "        [-0.2162,  0.4166, -0.4622, -1.1417]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding test\n",
    "\n",
    "embedding = nn.Embedding(35, 4)\n",
    "\n",
    "embedded_seq = embedding(X_tensor[0])\n",
    "embedded_seq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on loss function\n",
    "\n",
    "The competition uses TM-Score to evaluate predictions, which among other things is based on distance rather than absolute differences. As such, for my task, I will be converting both ground truth and predicted coordinates to distance matrices, and minimising loss between the two. Since it leverages  squared difference in distances, we'll use MSE (for now)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build initial simple model\n",
    "The architecture will consist of:\n",
    "- embedding: mapping integers corresponding to nucleotides in sequence to vectors representing semantic meanings\n",
    "- sequence encoder:  inspired by RibonanzaNet: 9 layers of 1D conv + residual, multi-head self-attention, and a feed-forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define blocks of the model\n",
    "\n",
    "class SeqEncoder(nn.Module): # Define single encoder block\n",
    "    def __init__(self, hidden_size=256, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv1d(hidden_size, hidden_size, kernel_size=kernel_size, padding = kernel_size // 2)\n",
    "        self.attn = nn.MultiheadAttention(hidden_size, 8)\n",
    "        self.norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.norm3 = nn.LayerNorm(hidden_size)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 4*hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*hidden_size, hidden_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.conv(X.transpose(1,2)).transpose(1,2) # 1D conv with residual connection + Layer Norm; transpose to expected input\n",
    "        X = self.norm1(X)\n",
    "        res = X\n",
    "        attn_out, _ = self.attn(X.transpose(0,1), X.transpose(0,1), X.transpose(0,1))\n",
    "        attn_out = attn_out.transpose(0,1) + res\n",
    "        X = self.norm2(attn_out)\n",
    "        res = X\n",
    "        X = self.norm3(res + self.ff(X))\n",
    "        return X\n",
    "        \n",
    "class ConvEncoder(nn.Module): # define a whole transformer pipeline\n",
    "    def __init__(self, n_blocks = 9, **kwargs):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([SeqEncoder(**kwargs) for _ in range(n_blocks)])\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model \n",
    "\n",
    "class InitModel(Module): # define rest of model\n",
    "    def __init__(self, seq_length=35, vocab=6, n_blocks=9, hidden_size=256):\n",
    "        super().__init__()\n",
    "        #self.b, self.l = X.size()\n",
    "        self.l = seq_length\n",
    "        self.b = vocab\n",
    "        self.embedding = nn.Embedding(self.l , hidden_size, padding_idx=0) # map each base to a vector representation of size 256\n",
    "        self.pos_embedding = nn.Embedding(self.l , hidden_size)\n",
    "        self.convencoder = ConvEncoder(n_blocks=n_blocks, hidden_size=hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, 3)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        # Make embeddings (+ positional embeddings)\n",
    "\n",
    "        X = self.embedding(X)\n",
    "        positions = torch.arange(self.l).unsqueeze(0).expand(X.size(0), self.l)\n",
    "        pos_embd = self.pos_embedding(positions)\n",
    "        X = X + pos_embd\n",
    "\n",
    "        # Pass through convolutional transformer\n",
    "\n",
    "        X = self.convencoder(X)\n",
    "\n",
    "        out = self.output(X)\n",
    "        return(out)\n",
    "\n",
    "        ## TO DO: add padding masks, add layers which map the encoded representations to coords, add distance calculation, minimise loss btwn og dist & encoded dist \n",
    "\n",
    "\n",
    "initmodel = InitModel()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  6.3101, 10.2222,  ..., 29.3938, 29.3938, 29.3938],\n",
       "        [ 6.3101,  0.0000,  5.2843,  ..., 31.1803, 31.1803, 31.1803],\n",
       "        [10.2222,  5.2843,  0.0000,  ..., 28.9600, 28.9600, 28.9600],\n",
       "        ...,\n",
       "        [29.3938, 31.1803, 28.9600,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [29.3938, 31.1803, 28.9600,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [29.3938, 31.1803, 28.9600,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make pairwise distance\n",
    "\n",
    "truth_seq = y_tensor[0]\n",
    "\n",
    "d_matrix = torch.zeros(truth_seq.size()[0], truth_seq.size()[0])\n",
    "\n",
    "for i in range(truth_seq.size()[0]):\n",
    "    i_coord = truth_seq[i]\n",
    "    for j in range(truth_seq.size()[0]):\n",
    "        j_coord = truth_seq[j]\n",
    "        d_matrix[i,j] = torch.norm(i_coord - j_coord)\n",
    "\n",
    "\n",
    "#def distance_mse_loss(pred, truth):\n",
    "\n",
    "d_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom loss function on distance matrices rather than coords\n",
    "\n",
    "def pairwise_distance_matrix(X):\n",
    "    diff = X.unsqueeze(2) - X.unsqueeze(1)  # shape: (batch, 35, 35, 5)\n",
    "    return torch.norm(diff, dim=-1)\n",
    "\n",
    "class DistanceMatrixLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = MSELoss()\n",
    "    \n",
    "    def forward(self, y_true, y_pred):\n",
    "        y_true_m = pairwise_distance_matrix(y_true)\n",
    "        y_pred_m = pairwise_distance_matrix(y_pred)\n",
    "        loss = self.loss(y_true_m, y_pred_m)\n",
    "        return loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss train 285.67, Loss Test 206.67\n",
      "Epoch 2: Loss train 191.1, Loss Test 147.29\n",
      "Epoch 3: Loss train 137.03, Loss Test 111.4\n",
      "Epoch 4: Loss train 111.21, Loss Test 98.1\n",
      "Epoch 5: Loss train 101.18, Loss Test 91.27\n",
      "Epoch 6: Loss train 91.03, Loss Test 62.54\n",
      "Epoch 7: Loss train 71.73, Loss Test 61.36\n",
      "Epoch 8: Loss train 60.41, Loss Test 55.12\n",
      "Epoch 9: Loss train 52.11, Loss Test 53.65\n",
      "Epoch 10: Loss train 51.01, Loss Test 45.95\n"
     ]
    }
   ],
   "source": [
    "from func import score\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "initmodel = InitModel()\n",
    "criterion = DistanceMatrixLoss()\n",
    "optimiser = Adam(initmodel.parameters())\n",
    "\n",
    "cols = [\"Epoch\", \"Train_Loss\", \"Test_Loss\", \"Train_TMScore\", \"Test_TMScore\"]\n",
    "perf = pd.DataFrame(index=range(n_epochs), columns=cols)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss_train = []\n",
    "    epoch_pred_train = []\n",
    "    epoch_true_train = []\n",
    "    initmodel.train()\n",
    "    for seq, coords in train_loader:\n",
    "        optimiser.zero_grad()\n",
    "        pred_coords = initmodel(seq)\n",
    "        loss = criterion(coords,pred_coords)\n",
    "        loss_train.append(loss.item())\n",
    "        epoch_pred_train.append(pred_coords.detach())\n",
    "        epoch_true_train.append(coords.detach())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    \n",
    "    #TMTrain = score(pd.DataFrame(epoch_true_train), pd.DataFrame(epoch_pred_train))\n",
    "    loss_train = sum(loss_train)/len(loss_train)\n",
    "\n",
    "    initmodel.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_test = []\n",
    "        epoch_pred_test = []\n",
    "        epoch_true_test = []\n",
    "        for seq, coords in test_loader:\n",
    "            pred_coords_test = initmodel(seq)\n",
    "            epoch_true_test.extend(coords)\n",
    "            epoch_pred_test.extend(pred_coords_test)\n",
    "            loss_test.append(criterion(coords, pred_coords_test).item())\n",
    "        \n",
    "        #TMTest = score(pd.DataFrame(epoch_true_test), pd.DataFrame(epoch_pred_test))\n",
    "        loss_test = sum(loss_test)/len(loss_test)\n",
    "    \n",
    "    #perf.iloc[epoch, :] = [epoch+1, loss_train, loss_test, TMTrain, TMTest]\n",
    "    print(f\"Epoch {epoch+1}: Loss train {round(loss_train, 2)}, Loss Test {round(loss_test, 2)}\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# TO DO: figure out TM Score (expects 2D dataframe of values), add padding masks, refine whole model, and train on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.1221, -1.5074, -3.5171],\n",
       "         [-6.6697, -0.9203, -1.8650],\n",
       "         [ 1.3617, -3.4590, -2.5066],\n",
       "         [-2.3103, -1.5089, -3.9034],\n",
       "         [ 4.7777, -4.9347, -0.9478],\n",
       "         [-6.5557,  0.7278, -1.0197],\n",
       "         [-6.3039, -0.7329, -3.0912],\n",
       "         [ 3.4688, -3.2465,  4.8137],\n",
       "         [ 0.5209,  4.0770, -1.2205],\n",
       "         [ 6.8408, -0.7116, -0.1893],\n",
       "         [ 1.5479,  3.5921, -4.1622],\n",
       "         [ 5.6581,  0.4541,  2.6360],\n",
       "         [-1.1962,  2.9436,  5.5144],\n",
       "         [-1.9997,  4.2526,  3.1709],\n",
       "         [-4.2152,  1.4335,  4.3036],\n",
       "         [ 6.2778, -1.4252,  4.2280],\n",
       "         [-3.7223,  4.9912, -2.2801],\n",
       "         [-2.1177, -5.9105, -0.7925],\n",
       "         [ 5.0614, -2.5719,  4.3367],\n",
       "         [-2.9110,  0.8523, -5.8743],\n",
       "         [ 4.9273, -2.6767,  4.7122],\n",
       "         [-6.2562,  3.0101,  0.8944],\n",
       "         [ 0.9202, -2.4327, -4.7375],\n",
       "         [-6.1439,  2.7268,  2.2095],\n",
       "         [-6.3950,  2.1013, -2.5844],\n",
       "         [ 3.2267,  0.4759,  3.1048],\n",
       "         [-0.5677,  2.9868,  5.0222],\n",
       "         [-6.8941,  2.5749,  1.1602],\n",
       "         [ 5.5506, -3.4051,  3.4340],\n",
       "         [-1.4695, -3.3431,  4.4900],\n",
       "         [ 2.7064, -1.8490,  4.0607],\n",
       "         [-4.7007,  3.4300,  2.2517],\n",
       "         [-2.7011,  2.4226, -6.3727],\n",
       "         [ 0.8858, -5.9156,  1.1710],\n",
       "         [ 0.6941,  2.2459, -5.7651]],\n",
       "\n",
       "        [[-4.2682, -2.0697, -4.1472],\n",
       "         [-5.2199, -1.1892,  1.3651],\n",
       "         [-0.3648, -0.3663, -6.3581],\n",
       "         [ 2.7042, -3.9363,  0.0105],\n",
       "         [ 4.5185, -2.3643,  0.4641],\n",
       "         [-6.1479,  2.6871, -3.2086],\n",
       "         [-3.6549, -3.3949, -2.3198],\n",
       "         [-2.5862,  1.1555,  5.0011],\n",
       "         [-3.7804,  2.7667, -5.2843],\n",
       "         [ 4.5124, -2.9630, -0.7937],\n",
       "         [ 0.4686,  3.7819,  1.1352],\n",
       "         [ 5.1438,  1.1971, -0.5221],\n",
       "         [ 4.5902,  0.0775,  5.0907],\n",
       "         [-3.7430,  5.0367, -1.3172],\n",
       "         [-1.0275,  0.9099,  3.6748],\n",
       "         [ 5.5499, -0.0962,  3.9946],\n",
       "         [-5.2224,  3.9700, -3.3234],\n",
       "         [-2.0179, -5.4496, -0.3859],\n",
       "         [ 4.2430, -1.6321,  5.2235],\n",
       "         [-1.1584,  1.2930, -5.7530],\n",
       "         [ 6.0591, -2.5349,  3.7796],\n",
       "         [-3.0887,  3.0460,  1.4107],\n",
       "         [ 4.1594, -0.6793, -3.9518],\n",
       "         [-6.3874,  2.9727, -1.3440],\n",
       "         [-4.7952, -0.3528, -2.2690],\n",
       "         [ 3.7842,  0.3005,  4.4812],\n",
       "         [ 3.6627,  1.6541,  4.5386],\n",
       "         [-3.4351,  3.9998, -0.5042],\n",
       "         [ 6.1341, -2.6204,  2.6656],\n",
       "         [-1.8149, -3.2168,  3.8992],\n",
       "         [ 2.4577, -1.7733,  4.0011],\n",
       "         [-4.6481,  3.2799,  1.9162],\n",
       "         [-2.8257,  2.3438, -6.1293],\n",
       "         [ 0.7327, -5.7692,  1.0243],\n",
       "         [ 0.3398,  2.1526, -5.6360]],\n",
       "\n",
       "        [[-4.7099, -1.6020, -3.6990],\n",
       "         [-6.4476, -0.2922, -1.1659],\n",
       "         [-3.0803, -0.3225, -5.2740],\n",
       "         [-2.6571, -3.2129, -3.3371],\n",
       "         [ 3.7226, -3.5978,  4.3592],\n",
       "         [-5.3260,  2.4341, -4.2022],\n",
       "         [ 1.3833, -4.8220,  2.2736],\n",
       "         [-3.8754,  1.9109,  0.5366],\n",
       "         [ 3.0435,  1.7160, -3.5969],\n",
       "         [ 1.9195,  2.3633, -2.0022],\n",
       "         [-2.3053,  1.5694, -5.4689],\n",
       "         [ 4.2006, -1.4076,  5.0491],\n",
       "         [ 2.4641,  2.7330,  4.6078],\n",
       "         [-2.8469,  4.4373, -1.3004],\n",
       "         [-2.1592, -0.6514,  5.4783],\n",
       "         [ 5.4713, -0.0323,  3.7983],\n",
       "         [-2.0327,  4.0684, -2.3421],\n",
       "         [-2.9600, -4.9828, -0.3880],\n",
       "         [ 3.4710, -3.0404,  3.2698],\n",
       "         [-2.5718, -0.7381, -5.8106],\n",
       "         [ 5.2611, -2.8145,  4.7299],\n",
       "         [-1.6190,  3.2843,  2.3891],\n",
       "         [ 4.0828, -1.0012, -5.1103],\n",
       "         [-0.7820,  1.4070,  4.5761],\n",
       "         [-4.7899,  1.7896, -4.5032],\n",
       "         [ 5.9367, -2.4247,  3.2104],\n",
       "         [ 2.9046,  2.3733,  4.1484],\n",
       "         [-0.6003,  2.6521,  1.9085],\n",
       "         [ 6.9713, -1.8081,  1.2997],\n",
       "         [ 0.6595, -2.7414,  3.4288],\n",
       "         [ 1.9418, -1.8521,  3.8622],\n",
       "         [-4.6342,  3.1449,  2.0748],\n",
       "         [-2.8463,  2.2769, -6.1198],\n",
       "         [ 0.7414, -5.7693,  1.0399],\n",
       "         [ 0.3942,  2.0320, -5.6835]],\n",
       "\n",
       "        [[-5.1453, -1.4786, -3.5133],\n",
       "         [-6.6289, -0.9133, -1.8003],\n",
       "         [ 0.7251, -3.1691, -2.0888],\n",
       "         [-1.5028, -1.7677, -4.5904],\n",
       "         [ 6.1825, -3.7379,  3.1343],\n",
       "         [-5.9426,  2.4824, -3.5560],\n",
       "         [-3.9952, -3.4003, -3.1054],\n",
       "         [ 2.2632, -2.0242,  5.4788],\n",
       "         [ 1.0430,  3.8598, -1.3145],\n",
       "         [ 6.8657, -0.6033, -0.0786],\n",
       "         [ 1.5641,  3.6285, -4.0678],\n",
       "         [ 5.6176,  0.4981,  2.6738],\n",
       "         [-1.1814,  2.9420,  5.5366],\n",
       "         [-1.9203,  4.2325,  3.2024],\n",
       "         [-4.1336,  1.4370,  4.3441],\n",
       "         [ 6.2657, -1.3847,  4.2506],\n",
       "         [-3.6843,  5.0139, -2.2200],\n",
       "         [-2.1602, -5.8834, -0.7486],\n",
       "         [ 5.0585, -2.5287,  4.3723],\n",
       "         [-2.9222,  0.8608, -5.8357],\n",
       "         [ 4.9205, -2.6423,  4.7421],\n",
       "         [-6.2631,  3.0348,  0.9255],\n",
       "         [ 0.9303, -2.4382, -4.6520],\n",
       "         [-6.1306,  2.7418,  2.2651],\n",
       "         [-6.3703,  2.1356, -2.5449],\n",
       "         [ 3.2044,  0.5041,  3.1568],\n",
       "         [-0.5113,  2.9844,  5.0483],\n",
       "         [-6.8538,  2.5857,  1.2035],\n",
       "         [ 5.5419, -3.3608,  3.4613],\n",
       "         [-1.4265, -3.2989,  4.5317],\n",
       "         [ 2.6767, -1.7908,  4.1405],\n",
       "         [-4.6864,  3.4613,  2.3165],\n",
       "         [-2.7190,  2.4673, -6.3298],\n",
       "         [ 0.8982, -5.8973,  1.2175],\n",
       "         [ 0.6810,  2.2667, -5.7302]],\n",
       "\n",
       "        [[-4.7248, -1.6860, -3.9336],\n",
       "         [-6.6059, -0.6314, -0.7205],\n",
       "         [-3.6753, -0.7061, -5.7406],\n",
       "         [-3.1474, -3.3803, -2.5584],\n",
       "         [ 2.7869, -3.5128,  0.7466],\n",
       "         [-6.9238,  1.1541, -3.1937],\n",
       "         [ 0.0245, -4.5873,  2.9169],\n",
       "         [ 2.5955,  2.5463,  2.6788],\n",
       "         [ 0.9228,  3.0416, -5.3007],\n",
       "         [ 4.6544, -0.9817,  1.0712],\n",
       "         [-1.9039,  3.9784, -3.7023],\n",
       "         [ 5.9334,  0.4972,  3.1158],\n",
       "         [ 0.5713,  2.9348,  4.6933],\n",
       "         [-0.8308,  4.1838,  1.3202],\n",
       "         [-5.0109,  2.5485,  3.6652],\n",
       "         [ 5.3333, -0.2839,  4.1835],\n",
       "         [-0.1964,  3.6891,  0.0563],\n",
       "         [-0.3423, -5.0787, -0.7465],\n",
       "         [ 6.4067, -1.9792,  3.2590],\n",
       "         [-0.1852,  1.4293, -5.9428],\n",
       "         [ 5.3631, -2.2073,  4.0129],\n",
       "         [-6.2274,  2.7790,  0.6176],\n",
       "         [ 0.8652, -2.4159, -4.8025],\n",
       "         [-6.1821,  2.6631,  2.0041],\n",
       "         [-6.3460,  2.0790, -2.6720],\n",
       "         [ 3.0524,  0.4280,  2.9536],\n",
       "         [-0.7324,  2.9613,  4.7897],\n",
       "         [-6.8713,  2.4887,  1.0078],\n",
       "         [ 5.4904, -3.4324,  3.3333],\n",
       "         [-1.5841, -3.3606,  4.2137],\n",
       "         [ 2.5085, -1.9078,  3.9210],\n",
       "         [-4.7392,  3.2864,  1.9499],\n",
       "         [-2.7254,  2.2994, -6.3267],\n",
       "         [ 0.7309, -5.9195,  0.9483],\n",
       "         [ 0.4632,  2.1006, -5.7922]],\n",
       "\n",
       "        [[-4.3101, -1.9237, -3.9118],\n",
       "         [-5.4053, -1.3088,  1.3104],\n",
       "         [ 0.8672, -1.3933, -5.8911],\n",
       "         [ 0.9020, -3.1508,  0.8918],\n",
       "         [ 4.4997, -3.9096, -1.9034],\n",
       "         [-4.5616,  1.3258, -2.1144],\n",
       "         [-6.1173, -0.2828, -2.7475],\n",
       "         [ 3.2643, -2.1885,  4.7409],\n",
       "         [-4.3092,  4.3640, -3.5205],\n",
       "         [ 5.2101, -2.2653, -1.6723],\n",
       "         [ 1.6961,  2.2637, -0.3481],\n",
       "         [ 5.2843,  1.6910,  1.1777],\n",
       "         [ 1.4387,  2.1419,  3.0446],\n",
       "         [-2.9269,  3.0004,  2.4145],\n",
       "         [-2.5257,  1.3667,  5.6973],\n",
       "         [ 6.7659, -1.0914,  2.7444],\n",
       "         [ 0.7195,  3.7827, -0.6440],\n",
       "         [ 2.1075, -5.4184,  1.6279],\n",
       "         [ 5.7643, -1.3201, -0.3630],\n",
       "         [ 3.3184, -1.5210, -2.8578],\n",
       "         [ 5.9950, -0.5632,  2.0178],\n",
       "         [ 0.1912,  1.5771,  3.7377],\n",
       "         [-2.8259,  0.7308, -5.7691],\n",
       "         [-4.2901,  0.5738,  0.2585],\n",
       "         [-6.3030,  1.5971, -2.0296],\n",
       "         [ 0.6352,  0.4269,  1.0927],\n",
       "         [ 1.2945,  1.4912,  4.7733],\n",
       "         [-4.7621,  2.4378,  3.1794],\n",
       "         [ 6.5629, -2.8755,  2.5028],\n",
       "         [ 4.5859, -1.7155,  3.2935],\n",
       "         [ 5.3011, -0.0522,  0.9365],\n",
       "         [-1.9946,  3.7023,  1.1031],\n",
       "         [-3.0966,  2.3846, -5.8223],\n",
       "         [ 0.8570, -5.6646,  0.9628],\n",
       "         [ 0.4028,  2.0235, -5.5819]],\n",
       "\n",
       "        [[-4.2550, -1.9633, -4.2732],\n",
       "         [-4.9151, -1.5709,  1.9118],\n",
       "         [-2.0228, -0.2816, -6.4313],\n",
       "         [ 0.1584, -4.6519, -1.0418],\n",
       "         [ 1.3994, -3.0651,  0.2271],\n",
       "         [-6.1786,  0.8547, -3.3920],\n",
       "         [-1.0832, -3.5012,  2.3701],\n",
       "         [-0.4622,  2.7125,  2.0118],\n",
       "         [ 1.8773,  3.2963, -3.2583],\n",
       "         [-3.5451,  1.4918, -4.7277],\n",
       "         [ 1.0102, -0.8576, -2.0170],\n",
       "         [ 4.8359,  0.0384,  4.3990],\n",
       "         [ 4.5145,  0.9155,  4.4015],\n",
       "         [ 1.2247,  4.8847, -0.1980],\n",
       "         [-1.5660,  1.7630,  3.8035],\n",
       "         [ 5.2198, -0.6504,  4.5677],\n",
       "         [-3.5513,  4.5754, -1.4773],\n",
       "         [-3.9775, -4.2862, -2.5614],\n",
       "         [ 5.4180, -3.6576,  3.5838],\n",
       "         [-1.5749,  1.8153, -3.4097],\n",
       "         [ 6.7624, -1.9971,  1.9735],\n",
       "         [-0.0410,  2.1631,  3.6558],\n",
       "         [-1.0691,  0.5485, -6.0414],\n",
       "         [ 1.5535,  0.3821,  4.0534],\n",
       "         [-5.2799,  3.4515, -3.3695],\n",
       "         [ 5.1848, -0.7617,  1.0030],\n",
       "         [-0.7430,  2.0336,  5.2797],\n",
       "         [-3.1943,  2.0980,  2.5226],\n",
       "         [ 7.0686, -2.0075,  1.3542],\n",
       "         [ 0.6192, -2.6365,  3.2897],\n",
       "         [ 2.1125, -1.7663,  3.8449],\n",
       "         [-4.5383,  3.2887,  1.9483],\n",
       "         [-2.7416,  2.3039, -6.1352],\n",
       "         [ 0.7383, -5.7242,  1.0058],\n",
       "         [ 0.4611,  2.0780, -5.6510]],\n",
       "\n",
       "        [[ 0.2988, -4.5483,  1.3598],\n",
       "         [-5.8948,  1.7063, -3.5865],\n",
       "         [ 2.3077, -2.4306, -4.9948],\n",
       "         [-4.7536, -0.6626, -2.0557],\n",
       "         [-0.7890, -4.2123, -1.0704],\n",
       "         [-6.6887,  0.3575, -1.7460],\n",
       "         [-5.7309, -1.9999, -1.2267],\n",
       "         [-0.9492, -1.0052,  3.7158],\n",
       "         [-0.6983,  2.8510, -4.9786],\n",
       "         [ 3.6820,  1.0112, -1.7445],\n",
       "         [-4.6393,  2.4379, -4.6665],\n",
       "         [ 3.8129, -1.8055,  4.9938],\n",
       "         [ 4.0761,  1.0920,  4.5570],\n",
       "         [ 4.3875,  2.2971,  3.0806],\n",
       "         [-2.5172,  3.3426, -0.7210],\n",
       "         [ 6.7781, -1.7762,  2.9309],\n",
       "         [-2.3941,  5.2417, -2.0478],\n",
       "         [-4.8087, -2.8891, -2.6250],\n",
       "         [ 5.1845, -2.8978,  3.8104],\n",
       "         [-4.5471,  1.4771, -5.1188],\n",
       "         [ 4.5453, -2.8451,  4.7326],\n",
       "         [-6.2283,  2.7328,  0.7067],\n",
       "         [ 0.7876, -2.5387, -4.7963],\n",
       "         [-6.1584,  2.5245,  1.9036],\n",
       "         [-6.3183,  1.9150, -2.7565],\n",
       "         [ 2.9945,  0.3170,  2.7852],\n",
       "         [-0.8028,  2.8457,  4.7188],\n",
       "         [-6.8954,  2.3653,  0.9448],\n",
       "         [ 5.4641, -3.4981,  3.2744],\n",
       "         [-1.6279, -3.4274,  4.1232],\n",
       "         [ 2.3911, -1.9705,  3.8352],\n",
       "         [-4.7493,  3.1256,  1.9361],\n",
       "         [-2.8321,  2.2161, -6.2843],\n",
       "         [ 0.7027, -5.9148,  0.8878],\n",
       "         [ 0.4648,  1.9645, -5.8285]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_coords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnafold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
